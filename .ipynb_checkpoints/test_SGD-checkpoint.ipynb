{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472ff886",
   "metadata": {},
   "source": [
    "# Test su SGD con Mini Batch per Kuramoto-Shinomoto-Sakaguchi MV-SDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98ef24",
   "metadata": {},
   "source": [
    "In primis importiamo i pacchetti necessari per usare le funzioni matematiche in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967e6a0",
   "metadata": {},
   "source": [
    "Scriviamo la MV-SDE relativa al modello di Kuramoto-Shinomoto-Sakaguchi, ovvero:\n",
    "\n",
    "$$ dX_t = \\left( \\mathbb{E}[sen(X_t)] cos(X_t) - \\mathbb{E}[cos(X_t)] sen(X_t) \\right) dt + \\sigma dW_t , \\ \\ \\ X_0=x_0. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d08153",
   "metadata": {},
   "source": [
    "Da questa equazione differenziale si evince che:\n",
    "* K = 3, d = 1 e q = 1,\n",
    "* $\\varphi(x)=(1, senx, cosx)$, \n",
    "* $\\alpha(t,x)=(0, cosx, -senx)^T$, \n",
    "* $\\beta(t,x)=(\\sigma, 0 , 0)^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cca7a8",
   "metadata": {},
   "source": [
    "Notiamo che, restando fedeli alla notazione e alla struttura del metodo Monte Carlo scritto precedentemente, siamo nel caso in cui $a_1=1$ e $a_2=1$. Come nel caso precedente, strutturiamo l'algoritmo in modo tale che abbia prima tutte le funzioni che svolgono il cuore del metodo, per poi richimarle nella parte finale ovvero nel main. Raccogliamo tutte le funzioni in differenti sezioni per poter meglio comprenderne il lavoro. Ciò è dato dal fatto che essendo tante funzioni si creerebbe troppa confusione poi nel leggere l'algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff9fa5",
   "metadata": {},
   "source": [
    "## Metodo di Eulero per la Simulazione di $Z(\\xi , W)$ e di $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af779d",
   "metadata": {},
   "source": [
    "Definiamo le due funzioni che ci permettono di simulare $Z(\\xi , W)$ e $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$, ovvero le soluzioni del sistema dato dalle seguenti equazioni differenziali:\n",
    "\n",
    "$$ dZ_t = \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right), \\ \\ \\ Z_0 = \\xi.$$\n",
    "\n",
    "$$ dY^{j,k}_t = g_j(t) \\nabla \\textbf{h}_k \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right) + \\sum_{i=0}^d Y^{j,k,i}_t  \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\partial_{z_i}\\alpha(t, Z_t)dt + \\partial_{z_i}\\beta(t, Z_t)dW_t\\right), \\ \\ \\ \\ Y^{j,k}_0 = 0,$$\n",
    "\n",
    "per $j = 0, \\cdots , n$ e $k = 1, \\cdots, K$.\n",
    "\n",
    "Ricordiamo che la prima equazione corrisponde alla $(13)$ del articolo e alla $(1.6)$ della mia bozza di tesi, mentre la seconda equazione corrisponde alla $(14)$ dell'articolo e alla $(1.8)$ della mia bozza di tesi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f629d",
   "metadata": {},
   "source": [
    "Vediamo ora le funzioni. Questa è quella che calcola la media di valori, identica al programma precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23a0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(Y):\n",
    "    num = Y.size\n",
    "    X = sum(Y) / num\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13a353",
   "metadata": {},
   "source": [
    "Questa funzione serve per creare la base dello spazio dei polinomi. Prende in input la dimensione $n$, il tempo $t$ nella quale i vettori della base devono essere calcolati e la tipologia di base scelta. Restituisce un vettore $n+1$ dimensionale che rappresenta gli elementi della base calcolati in $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87335224",
   "metadata": {},
   "source": [
    "* base canonica:   $g_i(t):= t^i$ con nodi equidistanti;\n",
    "* base di Lagrange: $g_i(t):=\\prod_{j \\leq n \\ e  \\ j\\neq n} \\left( \\frac{t - t_j}{t_i - t_j} \\right) $ con nodi di Chebyshev: $\\frac{a+b}{2} + \\frac{b-a}{2} cos \\left( \\frac{2k + 1}{2n +2} \\pi \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded2911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base(T, N, n, X0, tipo):\n",
    "    g = np.ones(n+1)\n",
    "    cc = np.linspace(0, T, N+1)\n",
    "    \n",
    "    if tipo == 'canonica':\n",
    "        g = np.array([ cc ** i for i in range(n+1)]) \n",
    "        \n",
    "        a1_0 = np.sin(X0) * g[:,0]\n",
    "        a2_0 = np.cos(X0) * g[:,0]\n",
    "        \n",
    "        return a1_0, a2_0, g\n",
    "    \n",
    "    elif tipo == 'lagrange':\n",
    "        l = [(0 + T)/2 + (T - 0)/2 * np.cos(((2 * i + 1)/ (2 * n + 2)) * math.pi) for i in range(n+1)]\n",
    "        \n",
    "        g = np.array([math.prod([((cc - l[j]) / (l[i] - l[j])) for j in range(n+1) if j!=i]) for i in range(n+1)])\n",
    "        \n",
    "        a1_0 = np.sin(X0) * np.ones(n+1) \n",
    "        a2_0 = np.cos(X0) * np.ones(n+1) \n",
    "\n",
    "        return a1_0, a2_0, g \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        return 'err'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d35afe",
   "metadata": {},
   "source": [
    "Osservazione: come abbiamo definito g, ovvero con i cicli dentro alla lista, effettivamente python richiede meno tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de5a2a",
   "metadata": {},
   "source": [
    "Scriviamo ora la funzione che svolge lo step di eulero per trovare la soluzione delle SDEs. In questo caso la funzione dovrà portare avanti 4 processi allo stesso tempo: $X$ e $Z$ monodimensionali e  le due $Y$ $n+1$ dimensionali. Inoltre la funzione dovrà usare ogni passo il valore ottenuto per il processo $X$ per poter calcolare le due $Y$. Notiamo che $X$ e $Z$ implementano lo step di eulero al medesimo modo del programma predecente, ma con due realizzazioni differenti del browniano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808e4bc",
   "metadata": {},
   "source": [
    "In questo algoritmo semplificato le mappe $\\textbf{h}$ e $ H $ sono prese rispettivamente come l'identià e la funzione nulla. Riprendendo i valori delle funzioni dei coefficienti per la MV-SDE relativa al modello di Kuramoto-Shninomoto-Sakaguchi si ottiene che nello specifico le equazioni diventano:\n",
    "\n",
    "$$ dZ_t = \\left( (\\mathcal{L}a)_1(t) cos(Z_t) - (\\mathcal{L}a)_2(t) sen(Z_t) \\right) dt + \\sigma dW_t, \\ \\ \\ Z_0 = X_0. $$\n",
    "\n",
    "$$ dY^{j,1}_t = \\left( g_j(t) cos(Z_t) - Y^{j,1}_t \\left( (\\mathcal{L}a)_1(t)sen(Z_t) + (\\mathcal{L}a)_2(t)cos(Z_t)\\right) \\right)dt, \\ \\ \\ Y^{j,1}_0 = 0,$$\n",
    "\n",
    "$$ dY^{j,2}_t = \\left( -g_j(t) sen(Z_t) - Y^{j,2}_t \\left( (\\mathcal{L}a)_1(t)sen(Z_t) + (\\mathcal{L}a)_2(t)cos(Z_t)\\right) \\right)dt, \\ \\ \\ Y^{j,2}_0 = 0,$$\n",
    "per $j = 0, \\cdots , n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca80ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_eulero(c1, c2, sigma, i, h, M, X, Z, YY1, YY2, g):\n",
    "    W = np.random.normal(0, 1, (2, M)) \n",
    "    \n",
    "    X = X + (c1 * np.cos(X) - c2 * np.sin(X)) * h + sigma * math.sqrt(h) * W[0] \n",
    "    \n",
    "    YY1 = YY1 + ((g[:,i] * np.ones((M, 1))).transpose() * np.cos(Z) - YY1 * (c1 * np.sin(Z) + c2 * np.cos(Z))) * h\n",
    "    YY2 = YY2 + ((-g[:,i] * np.ones((M, 1))).transpose() * np.sin(Z) - YY2 * (c1 * np.sin(Z) + c2 * np.cos(Z))) * h\n",
    "    \n",
    "    Z = Z + (c1 * np.cos(Z) - c2 * np.sin(Z)) * h + sigma * math.sqrt(h) * W[1]\n",
    "    \n",
    "    \n",
    "    return X, Z, YY1, YY2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32511a0f",
   "metadata": {},
   "source": [
    "Questa funzione genera effetivamente le soluzioni $X$, $Z$, $Y_1$ e $Y_2$. Inizianizzando le prime due come il valore $Z_0$ che viene passato in input, applica per tutti gli istanti fino all' N-esimo lo step di eulero richiamando la funzine precedente. Notiamo che in ogni passo calcoliamo le costanti $c_1$ e $c_2$, ovvero il valore del polinomio al tempo $t$ che appossima le funzioni seno e coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67727f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eulero(a1, a2, sigma, n, N, M, Z0, h, g):\n",
    "    \n",
    "    X = Z0 * np.ones((N+1, M))\n",
    "    Z = Z0 * np.ones((N+1, M))\n",
    "    Y1 = np.zeros((N+1, n+1, M))\n",
    "    Y2 = np.zeros((N+1, n+1, M))\n",
    "    \n",
    "    for i in range(N):\n",
    "        c1 = np.dot(a1, g[:,i])\n",
    "        c2 = np.dot(a2, g[:,i])\n",
    "        YY1 = Y1[i]\n",
    "        YY2 = Y2[i]\n",
    "        X[i+1], Z[i+1], Y1[i+1], Y2[i+1] = step_eulero(c1, c2, sigma, i, h, M, X[i], Z[i], YY1, YY2, g)\n",
    "    \n",
    "    return X, Z, Y1, Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bac12",
   "metadata": {},
   "source": [
    "## Metodo di Discesa del Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5da8f",
   "metadata": {},
   "source": [
    "In questa sezione ci sono le due funzioni cardine del codice. La prima serve a calcolare la realizzazione del gradiente per la discesa stocastica, ovvero la funzione $v$ descritta nella (17) dell'articolo. In generale la scrittura di $v$, componente per componente, è la seguente:\n",
    "\n",
    "$$v_{h,j}(a; \\xi, W; \\tilde{\\xi}, \\tilde{W}) = 2 \\int_0^T \\langle \\varphi (Z^a_t(\\xi,W)) - \\textbf{h} ((\\mathcal{L}a)(t)), \\nabla_x \\varphi (Z^a_t(\\tilde{\\xi}, \\tilde{W})) Y_t^{a;h,j}(\\tilde{\\xi}, \\tilde{W}) - \\partial_{a_{h,j}}\\textbf{h}((\\mathcal{L}a)(t))\\rangle dt, $$ \n",
    "con $h = 0, \\cdots , n$ e $j = 1, \\cdots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3e8a5",
   "metadata": {},
   "source": [
    "Come nei casi precedenti scriviamo questa e quazione nel caso specifico del nostro algoritmo. Avendo suddiviso il tempo in N steps temporali, approssimiamo l'integrale con una sommatoria.\n",
    "\n",
    "$$v_{j,1}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( sen(Z^a_t(W)) - (\\mathcal{L}a)_1(t) \\right) \\cdot \\left( cos(Z^a_t(\\tilde{W})) Y_t^{a;j,1}(\\tilde{W}) - g_j(t) \\right) + \\left( cos(Z^a_t(W)) - (\\mathcal{L}a)_2(t) \\right) \\cdot \\left( -sen(Z^a_t(\\tilde{W})) Y_t^{a;j,1}(\\tilde{W}) \\right)\\right], $$ \n",
    "\n",
    "$$v_{j,2}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( sen(Z^a_t(W)) - (\\mathcal{L}a)_1(t) \\right) \\cdot \\left( cos(Z^a_t(\\tilde{W})) Y_t^{a;j,2}(\\tilde{W}) \\right) + \\left( cos(Z^a_t(W)) - (\\mathcal{L}a)_2(t) \\right) \\cdot \\left( -sen(Z^a_t(\\tilde{W})) Y_t^{a;j,2}(\\tilde{W}) - g_j(t) \\right)\\right], $$  \n",
    "con $j = 0, \\cdots , n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e9a7f",
   "metadata": {},
   "source": [
    "Notiamo che prima di restituire il valore $v$ questa fuzione fa una media. Esso serve nel caso $M>1$ in cui sfruttiamo molteplici simulzioni del browniano per aver una miglior stima di $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecde5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(Z, Ztilde, Y1tilde, Y2tilde, a1, a2, n, M, h, g):\n",
    "    v1 = np.zeros(n+1)\n",
    "    v2 = np.zeros(n+1)\n",
    "    \n",
    "    for j in range(n+1): \n",
    "        \n",
    "        q1 = np.sin(Z) - (np.dot(a1,g) * np.ones((M, 1))).transpose()\n",
    "        q2 = np.cos(Ztilde) * Y1tilde[:,j] - (g[j,:] * np.ones((M, 1))).transpose()\n",
    "        q3 = np.cos(Z) - (np.dot(a2,g) * np.ones((M, 1))).transpose()\n",
    "        q4 = -np.sin(Ztilde) * Y1tilde[:,j]\n",
    "        \n",
    "        v1[j] = average( 2 * h * sum(q1 * q2 + q3 * q4 ) ) \n",
    "        \n",
    "        q1 = np.sin(Z) - (np.dot(a1,g) * np.ones((M, 1))).transpose()\n",
    "        q2 = np.cos(Ztilde) * Y2tilde[:,j] \n",
    "        q3 = np.cos(Z) - (np.dot(a2,g) * np.ones((M, 1))).transpose() \n",
    "        q4 = -np.sin(Ztilde) * Y2tilde[:,j] - (g[j,:] * np.ones((M, 1))).transpose()\n",
    "        \n",
    "        v2[j] = average( 2 * h * sum( q1 * q2 + q3 * q4 ) )\n",
    "\n",
    "    return v1, v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abefdd",
   "metadata": {},
   "source": [
    "La seconda serve semplicemente ad applicare il meodo di discesa. Essa non fa altro che richiamare ciclicamente le precedenti funzioni che generano le soluzoni delle SDEs per ogni istante di tempo e richiamare la funzione gradiente che sfrutta quelle soluzioni per calcolare il valore di $v$ da mettere nel passo del metodo di discesa. Notiamo che tra i paramentri c'è anche $M$ che se lasciato a 1 rende il metodo un classico metodo SGD, ma se portato a $\\infty$ porta a un metodo GD.\n",
    "\n",
    "Inoltre questa funzione che ci permette di ottenere il numero di step di convergenza del metodo di Discesa del Gradiente. La funzione controlla che la norma $L_2$ dell'errore relativo tra il polinomio soluzione della iterata $m-$esima e $(m+1)-$esima sia minore di una certa tolleranza. Questa condizione dovrà essere verificata per tre iterazioni succesive, affinché il ciclo si fermi, in quanto, basandosi su processi che dipendono da valori aleatori, può capitare che in uno step la differenza rispetto a quello successivo sia molto piccola, pur non essendo giunti a convergenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cfb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discesa_stocastica_del_gradiente(a1_0, a2_0, n, r0, rho, sigma, N, M, X0, eps, h, g):\n",
    "    a1 = a1_0 \n",
    "    a2 = a2_0\n",
    "    m = 0\n",
    "    cont = [[eps+1, eps+1, eps+1], [eps+1, eps+1, eps+1]] \n",
    "    \n",
    "    while ((cont[0][-1] >= eps) or (cont[0][-2] >= eps) or (cont[0][-3] >= eps)) or ((cont[1][-1] >= eps) or (cont[1][-2] >= eps) or (cont[1][-3] >= eps)):\n",
    "        eta = r0 / ((m + 1) ** rho)\n",
    "        \n",
    "        Z, Ztilde, Y1tilde, Y2tilde = eulero(a1, a2, sigma, n, N, M, X0, h, g)\n",
    "        \n",
    "        v1, v2 = gradiente(Z, Ztilde, Y1tilde, Y2tilde, a1, a2, n, M, h, g) \n",
    "        \n",
    "        a1_succ = a1 - eta * v1\n",
    "        a2_succ = a2 - eta * v2\n",
    "        \n",
    "        cont[0].append( LA.norm(np.dot(a1,g) - np.dot(a1_succ,g)) / LA.norm(np.dot(a1,g)) )\n",
    "        cont[1].append( LA.norm(np.dot(a2,g) - np.dot(a2_succ,g)) / LA.norm(np.dot(a2,g)) )\n",
    "        m = m + 1\n",
    "        \n",
    "        a1 = a1_succ\n",
    "        a2 = a2_succ\n",
    "        \n",
    "        if m >= 50000:\n",
    "            break\n",
    "        \n",
    "    return a1, a2, m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e00b41",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04ab48",
   "metadata": {},
   "source": [
    "Concludiamo riportando il main che richiama le funzioni sopra definite. Ricordiamo a cosa corrisponderanno i valori che daremo in input alle funzioni che richiameremo:\n",
    "* N : numero di iterazioni (steps temporali),\n",
    "* M : numero di simulazioni in ogni istante,\n",
    "* T : istante finale,\n",
    "* $\\mu$ : funzione di Drift,\n",
    "* $\\sigma$ : funzione di Diffuzione,\n",
    "* h : step temporale,\n",
    "* $X_0$ : dato iniziale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40527834",
   "metadata": {},
   "source": [
    "Richiameremo inoltre:\n",
    "* n: dimensione dello spazio dei polinomi,\n",
    "* $a_0$: valore iniziale del vettore del metodo SGD. Ora è semplificata, poi ci mettiamo lo sviluppo di Taylor di Kolmogorov di gamma1+gamma2,\n",
    "* $r_0$ e $\\rho$: servono per i learning rates e devono essere  $r_0 \\in (0, +\\infty)$ e $\\frac{1}{2} < \\rho \\leq 1$ ,\n",
    "* m: num di step per il mtodo SGD,\n",
    "* M: mini batch tra SGD e GD,\n",
    "* $\\epsilon$: tolleranza errore relativo dell' 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1e927",
   "metadata": {},
   "source": [
    "Ricordiamo inoltre che siamo in un caso semplificato in cui non ci sono le due mappe ausiliarie $H$ e $\\textbf{h}$, ovvero:\n",
    "* H = 0\n",
    "* $\\textbf{h}$ = identità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e9e0122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero m di step per avere convergenza con M = 1 :\n",
      " \n",
      "  rho \\ r0    0.1    0.5    1    10\n",
      "----------  -----  -----  ---  ----\n",
      "       0.6      4     19   64  1280\n",
      "       0.7      3     15   49   555\n",
      "       0.8      3     17   24   355\n",
      "       0.9      4     14   16   196\n",
      " \n",
      " \n",
      "Numero m di step per avere convergenza con M = 10 :\n",
      " \n",
      "  rho \\ r0    0.1    0.5    1    10\n",
      "----------  -----  -----  ---  ----\n",
      "       0.6      3      6   16   330\n",
      "       0.7      3      6   11   166\n",
      "       0.8      3      5   12   119\n",
      "       0.9      3      4    7    50\n",
      " \n",
      " \n",
      "Numero m di step per avere convergenza con M = 100 :\n",
      " \n",
      "  rho \\ r0    0.1    0.5    1    10\n",
      "----------  -----  -----  ---  ----\n",
      "       0.6      3      5    5    79\n",
      "       0.7      3      4    5    58\n",
      "       0.8      3      4    5    34\n",
      "       0.9      3      4    5    24\n",
      " \n",
      " \n",
      "Numero m di step per avere convergenza con M = 1000 :\n",
      " \n",
      "  rho \\ r0    0.1    0.5    1    10\n",
      "----------  -----  -----  ---  ----\n",
      "       0.6      3      3    4    23\n",
      "       0.7      3      3    4    14\n",
      "       0.8      3      3    4    10\n",
      "       0.9      3      3    4    13\n",
      " \n",
      " \n",
      "Numero m di step per avere convergenza con M = 10000 :\n",
      " \n",
      "  rho \\ r0    0.1    0.5    1    10\n",
      "----------  -----  -----  ---  ----\n",
      "       0.6      3      3    4    13\n",
      "       0.7      3      3    4    11\n",
      "       0.8      3      3    4     9\n",
      "       0.9      3      3    4     9\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Parametri in Input vecchi\n",
    "\n",
    "    sigma = 0.5\n",
    "    T = 1\n",
    "    N = 100\n",
    "    X0 = 0.5\n",
    "    h = T / N\n",
    "\n",
    "    # Parametri in Input nuovi\n",
    "\n",
    "    n = 5   \n",
    "    r0 = [0.1, 0.5, 1, 10]\n",
    "    rho = [0.6, 0.7, 0.8, 0.9]\n",
    "    M = [1, 10, 100, 1000, 10000] \n",
    "    eps = 0.01\n",
    "    tipo = 'lagrange'\n",
    "\n",
    "    a1_0, a2_0, g = base(T, N, n, X0, tipo)\n",
    "    m = np.zeros((len(r0), len(rho)+1, len(M)))\n",
    "    for i in range(len(M)):\n",
    "        m[:,0,i] = rho\n",
    "\n",
    "\n",
    "    for p in range(len(M)):\n",
    "\n",
    "        print(\"Numero m di step per avere convergenza con M = \"+str(M[p])+\" :\")\n",
    "        print(\" \")\n",
    "\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                # start = time.process_time()   # parte il cronometro \n",
    "                a1, a2, m[j,i+1,p] = discesa_stocastica_del_gradiente(a1_0, a2_0, n, r0[i], rho[j], sigma, N, M[p], X0, eps, h, g) \n",
    "                end = time.process_time()   # si ferma il cronometro \n",
    "\n",
    "                # print(\"Tempo di esecuzione con r0=\"+str(r0[i])+\" e rho=\"+str(rho[j])+\": \", end - start)\n",
    "                # print(m[j,i+1,p])\n",
    "\n",
    "        print(tabulate(m[:,:,p], headers=[\"rho \\ r0\", str(r0[0]), str(r0[1]), str(r0[2]), str(r0[3])]))\n",
    "        print(\" \")\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03823269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
