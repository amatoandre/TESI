{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472ff886",
   "metadata": {},
   "source": [
    "# Test su SGD con Mini Batch per Kuramoto-Shinomoto-Sakaguchi MV-SDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98ef24",
   "metadata": {},
   "source": [
    "In primis importiamo i pacchetti necessari per usare le funzioni matematiche in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e25496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from numpy import mean\n",
    "from tabulate import tabulate\n",
    "\n",
    "def average(Y):\n",
    "    num = Y.size\n",
    "    X = sum(Y) / num\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967e6a0",
   "metadata": {},
   "source": [
    "Scriviamo la MV-SDE relativa al modello di Kuramoto-Shinomoto-Sakaguchi, ovvero:\n",
    "\n",
    "$$ dX_t = \\left( \\mathbb{E}[sen(X_t)] cos(X_t) - \\mathbb{E}[cos(X_t)] sen(X_t) \\right) dt + \\sigma dW_t , \\ \\ \\ X_0=x_0. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d08153",
   "metadata": {},
   "source": [
    "Da questa equazione differenziale si evince che:\n",
    "* K = 3, d = 1 e q = 1,\n",
    "* $\\varphi(x)=(1, senx, cosx)$, \n",
    "* $\\alpha(t,x)=(0, cosx, -senx)^T$, \n",
    "* $\\beta(t,x)=(\\sigma, 0 , 0)^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b2833",
   "metadata": {},
   "source": [
    "## Metodo di Eulero - Monte Carlo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7bcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eulero1(c1, c2, sigma, h, M, X):\n",
    "    W = np.random.normal(0, 1, M) \n",
    "    drift = c1 * np.cos(X) - c2 * np.sin(X) \n",
    "    diffusione = sigma \n",
    "    X = X + drift * h + diffusione * math.sqrt(h) * W \n",
    "    \n",
    "    return X\n",
    "\n",
    "def monte_carlo(c1, c2, a1, a2, sigma, T, N, M, X0):\n",
    "    h = T / N\n",
    "    X = X0 * np.ones(M)\n",
    "    gamma1 = [average(np.sin(X))]\n",
    "    gamma2 = [average(np.cos(X))]\n",
    "    \n",
    "    for i in range(N):\n",
    "        X = eulero1(c1 + a1 * gamma1[-1], c2 + a2 * gamma2[-1], sigma, h, M, X)\n",
    "        gamma1.append(average(np.sin(X)))\n",
    "        gamma2.append(average(np.cos(X)))\n",
    "    \n",
    "    return X, gamma1, gamma2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057b80b",
   "metadata": {},
   "source": [
    "## Metodo di Discesa del Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff9fa5",
   "metadata": {},
   "source": [
    "### Metodo di Eulero per la Simulazione di $Z(\\xi , W)$ e di $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af779d",
   "metadata": {},
   "source": [
    "Definiamo le due funzioni che ci permettono di simulare $Z(\\xi , W)$ e $\\left( Z^a(\\tilde{\\xi} , \\tilde{W}), \\partial_{a_{h,j}} Z^a(\\tilde{\\xi} , \\tilde{W}) \\right)$, ovvero le soluzioni del sistema dato dalle seguenti equazioni differenziali:\n",
    "\n",
    "$$ dZ_t = \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right), \\ \\ \\ Z_0 = \\xi.$$\n",
    "\n",
    "$$ dY^{j,k}_t = g_j(t) \\nabla \\textbf{h}_k \\left((\\mathcal{L}a)(t)\\right) \\left( \\alpha(t, Z_t)dt + \\beta(t, Z_t)dW_t\\right) + \\sum_{i=0}^d Y^{j,k,i}_t  \\textbf{h} \\left((\\mathcal{L}a)(t)\\right) \\left( \\partial_{z_i}\\alpha(t, Z_t)dt + \\partial_{z_i}\\beta(t, Z_t)dW_t\\right), \\ \\ \\ \\ Y^{j,k}_0 = 0,$$\n",
    "\n",
    "per $j = 0, \\cdots , n$ e $k = 1, \\cdots, K$.\n",
    "\n",
    "Ricordiamo che la prima equazione corrisponde alla $(13)$ del articolo e alla $(1.6)$ della mia bozza di tesi, mentre la seconda equazione corrisponde alla $(14)$ dell'articolo e alla $(1.8)$ della mia bozza di tesi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13a353",
   "metadata": {},
   "source": [
    "Questa funzione serve per creare la base dello spazio dei polinomi. Prende in input la dimensione $n$, il tempo $t$ nella quale i vettori della base devono essere calcolati e la tipologia di base scelta. Restituisce un vettore $n+1$ dimensionale che rappresenta gli elementi della base calcolati in $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87335224",
   "metadata": {},
   "source": [
    "* base canonica:   $g_i(t):= t^i$ con nodi equidistanti;\n",
    "* base di Lagrange: $g_i(t):=\\prod_{j \\leq n \\ e  \\ j\\neq n} \\left( \\frac{t - t_j}{t_i - t_j} \\right) $ con nodi di Chebyshev: $\\frac{a+b}{2} + \\frac{b-a}{2} cos \\left( \\frac{2k + 1}{2n +2} \\pi \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded2911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base(T, N, n, X0, tipo):\n",
    "    g = np.ones(n+1)\n",
    "    cc = np.linspace(0, T, N+1)\n",
    "    \n",
    "    if tipo == 'canonica':\n",
    "        g = np.array([ cc ** i for i in range(n+1)]) \n",
    "        \n",
    "        a1_0 = np.sin(X0) * g[:,0]\n",
    "        a2_0 = np.cos(X0) * g[:,0]\n",
    "        \n",
    "        return a1_0, a2_0, g\n",
    "    \n",
    "    elif tipo == 'lagrange':\n",
    "        l = [(0 + T)/2 + (T - 0)/2 * np.cos(((2 * i + 1)/ (2 * n + 2)) * math.pi) for i in range(n+1)]\n",
    "        \n",
    "        g = np.array([math.prod([((cc - l[j]) / (l[i] - l[j])) for j in range(n+1) if j!=i]) for i in range(n+1)])\n",
    "        \n",
    "        a1_0 = np.sin(X0) * np.ones(n+1) \n",
    "        a2_0 = np.cos(X0) * np.ones(n+1) \n",
    "\n",
    "        return a1_0, a2_0, g \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        return 'err'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808e4bc",
   "metadata": {},
   "source": [
    "In questo algoritmo semplificato le mappe $\\textbf{h}$ e $ H $ sono prese rispettivamente come l'identià e la funzione nulla. Riprendendo i valori delle funzioni dei coefficienti per la MV-SDE relativa al modello di Kuramoto-Shninomoto-Sakaguchi si ottiene che nello specifico le equazioni diventano:\n",
    "\n",
    "$$ dZ_t = \\left( (\\mathcal{L}a)_1(t) cos(Z_t) - (\\mathcal{L}a)_2(t) sen(Z_t) \\right) dt + \\sigma dW_t, \\ \\ \\ Z_0 = X_0. $$\n",
    "\n",
    "$$ dY^{j,1}_t = \\left( g_j(t) cos(Z_t) - Y^{j,1}_t \\left( (\\mathcal{L}a)_1(t)sen(Z_t) + (\\mathcal{L}a)_2(t)cos(Z_t)\\right) \\right)dt, \\ \\ \\ Y^{j,1}_0 = 0,$$\n",
    "\n",
    "$$ dY^{j,2}_t = \\left( -g_j(t) sen(Z_t) - Y^{j,2}_t \\left( (\\mathcal{L}a)_1(t)sen(Z_t) + (\\mathcal{L}a)_2(t)cos(Z_t)\\right) \\right)dt, \\ \\ \\ Y^{j,2}_0 = 0,$$\n",
    "per $j = 0, \\cdots , n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca80ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_eulero(c1, c2, sigma, i, h, M, X, Z, YY1, YY2, g):\n",
    "    W = np.random.normal(0, 1, (2, M)) \n",
    "    \n",
    "    X = X + (c1 * np.cos(X) - c2 * np.sin(X)) * h + sigma * math.sqrt(h) * W[0] \n",
    "    \n",
    "    YY1 = YY1 + ((g[:,i] * np.ones((M, 1))).transpose() * np.cos(Z) - YY1 * (c1 * np.sin(Z) + c2 * np.cos(Z))) * h\n",
    "    YY2 = YY2 + ((-g[:,i] * np.ones((M, 1))).transpose() * np.sin(Z) - YY2 * (c1 * np.sin(Z) + c2 * np.cos(Z))) * h\n",
    "    \n",
    "    Z = Z + (c1 * np.cos(Z) - c2 * np.sin(Z)) * h + sigma * math.sqrt(h) * W[1]\n",
    "    \n",
    "    \n",
    "    return X, Z, YY1, YY2\n",
    "\n",
    "def eulero(a1, a2, sigma, n, N, M, Z0, h, g):\n",
    "    \n",
    "    X = Z0 * np.ones((N+1, M))\n",
    "    Z = Z0 * np.ones((N+1, M))\n",
    "    Y1 = np.zeros((N+1, n+1, M))\n",
    "    Y2 = np.zeros((N+1, n+1, M))\n",
    "    \n",
    "    for i in range(N):\n",
    "        c1 = np.dot(a1, g[:,i])\n",
    "        c2 = np.dot(a2, g[:,i])\n",
    "        YY1 = Y1[i]\n",
    "        YY2 = Y2[i]\n",
    "        X[i+1], Z[i+1], Y1[i+1], Y2[i+1] = step_eulero(c1, c2, sigma, i, h, M, X[i], Z[i], YY1, YY2, g)\n",
    "    \n",
    "    return X, Z, Y1, Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bac12",
   "metadata": {},
   "source": [
    "### Metodo di Discesa "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5da8f",
   "metadata": {},
   "source": [
    "In questa sezione ci sono le due funzioni cardine del codice. La prima serve a calcolare la realizzazione del gradiente per la discesa stocastica, ovvero la funzione $v$ descritta nella (17) dell'articolo. In generale la scrittura di $v$, componente per componente, è la seguente:\n",
    "\n",
    "$$v_{h,j}(a; \\xi, W; \\tilde{\\xi}, \\tilde{W}) = 2 \\int_0^T \\langle \\varphi (Z^a_t(\\xi,W)) - \\textbf{h} ((\\mathcal{L}a)(t)), \\nabla_x \\varphi (Z^a_t(\\tilde{\\xi}, \\tilde{W})) Y_t^{a;h,j}(\\tilde{\\xi}, \\tilde{W}) - \\partial_{a_{h,j}}\\textbf{h}((\\mathcal{L}a)(t))\\rangle dt, $$ \n",
    "con $h = 0, \\cdots , n$ e $j = 1, \\cdots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3e8a5",
   "metadata": {},
   "source": [
    "Come nei casi precedenti scriviamo questa e quazione nel caso specifico del nostro algoritmo. Avendo suddiviso il tempo in N steps temporali, approssimiamo l'integrale con una sommatoria.\n",
    "\n",
    "$$v_{j,1}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( sen(Z^a_t(W)) - (\\mathcal{L}a)_1(t) \\right) \\cdot \\left( cos(Z^a_t(\\tilde{W})) Y_t^{a;j,1}(\\tilde{W}) - g_j(t) \\right) + \\left( cos(Z^a_t(W)) - (\\mathcal{L}a)_2(t) \\right) \\cdot \\left( -sen(Z^a_t(\\tilde{W})) Y_t^{a;j,1}(\\tilde{W}) \\right)\\right], $$ \n",
    "\n",
    "$$v_{j,2}(a; W; \\tilde{W}) = 2 h \\sum_{t=0}^{N} \\left[ \\left( sen(Z^a_t(W)) - (\\mathcal{L}a)_1(t) \\right) \\cdot \\left( cos(Z^a_t(\\tilde{W})) Y_t^{a;j,2}(\\tilde{W}) \\right) + \\left( cos(Z^a_t(W)) - (\\mathcal{L}a)_2(t) \\right) \\cdot \\left( -sen(Z^a_t(\\tilde{W})) Y_t^{a;j,2}(\\tilde{W}) - g_j(t) \\right)\\right], $$  \n",
    "con $j = 0, \\cdots , n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e9a7f",
   "metadata": {},
   "source": [
    "Notiamo che prima di restituire il valore $v$ questa fuzione fa una media. Esso serve nel caso $M>1$ in cui sfruttiamo molteplici simulzioni del browniano per aver una miglior stima di $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecde5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(Z, Ztilde, Y1tilde, Y2tilde, a1, a2, n, M, h, g):\n",
    "    v1 = np.zeros(n+1)\n",
    "    v2 = np.zeros(n+1)\n",
    "    \n",
    "    for j in range(n+1): \n",
    "        \n",
    "        q1 = np.sin(Z) - (np.dot(a1,g) * np.ones((M, 1))).transpose()\n",
    "        q2 = np.cos(Ztilde) * Y1tilde[:,j] - (g[j,:] * np.ones((M, 1))).transpose()\n",
    "        q3 = np.cos(Z) - (np.dot(a2,g) * np.ones((M, 1))).transpose()\n",
    "        q4 = -np.sin(Ztilde) * Y1tilde[:,j]\n",
    "        \n",
    "        v1[j] = average( 2 * h * sum(q1 * q2 + q3 * q4 ) ) \n",
    "        \n",
    "        q1 = np.sin(Z) - (np.dot(a1,g) * np.ones((M, 1))).transpose()\n",
    "        q2 = np.cos(Ztilde) * Y2tilde[:,j] \n",
    "        q3 = np.cos(Z) - (np.dot(a2,g) * np.ones((M, 1))).transpose() \n",
    "        q4 = -np.sin(Ztilde) * Y2tilde[:,j] - (g[j,:] * np.ones((M, 1))).transpose()\n",
    "        \n",
    "        v2[j] = average( 2 * h * sum( q1 * q2 + q3 * q4 ) )\n",
    "\n",
    "    return v1, v2\n",
    "\n",
    "def discesa_stocastica_del_gradiente(a1_0, a2_0, n, r0, rho, sigma, N, M, X0, eps, h, g, gamma1, gamma2):\n",
    "    a1 = a1_0 \n",
    "    a2 = a2_0\n",
    "\n",
    "    norma1 = LA.norm(gamma1)\n",
    "    norma2 = LA.norm(gamma2)\n",
    "    \n",
    "    for m in range(50000):\n",
    "        \n",
    "        if (m % 10 == 0):\n",
    "            if ( ((LA.norm(np.dot(a1,g) - gamma1)/ norma1) < eps) and ((LA.norm(np.dot(a2,g) - gamma2)/ norma2) < eps) ):\n",
    "                break\n",
    "            \n",
    "        eta = r0 / ((m + 1) ** rho) \n",
    "        \n",
    "        Z, Ztilde, Y1tilde, Y2tilde = eulero(a1, a2, sigma, n, N, M, X0, h, g)\n",
    "        \n",
    "        v1, v2 = gradiente(Z, Ztilde, Y1tilde, Y2tilde, a1, a2, n, M, h, g) \n",
    "        \n",
    "        a1 = a1 - eta * v1\n",
    "        a2 = a2 - eta * v2\n",
    "        \n",
    "    return a1, a2, m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e00b41",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04ab48",
   "metadata": {},
   "source": [
    "Concludiamo riportando il main che richiama le funzioni sopra definite. Ricordiamo a cosa corrisponderanno i valori che daremo in input alle funzioni che richiameremo:\n",
    "* N : numero di iterazioni (steps temporali),\n",
    "* M : numero di simulazioni in ogni istante,\n",
    "* T : istante finale,\n",
    "* $\\mu$ : funzione di Drift,\n",
    "* $\\sigma$ : funzione di Diffuzione,\n",
    "* h : step temporale,\n",
    "* $X_0$ : dato iniziale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40527834",
   "metadata": {},
   "source": [
    "Richiameremo inoltre:\n",
    "* n: dimensione dello spazio dei polinomi,\n",
    "* $a_0$: valore iniziale del vettore del metodo SGD. Ora è semplificata, poi ci mettiamo lo sviluppo di Taylor di Kolmogorov di gamma1+gamma2,\n",
    "* $r_0$ e $\\rho$: servono per i learning rates e devono essere  $r_0 \\in (0, +\\infty)$ e $\\frac{1}{2} < \\rho \\leq 1$ ,\n",
    "* m: num di step per il mtodo SGD,\n",
    "* M: mini batch tra SGD e GD,\n",
    "* $\\epsilon$: tolleranza errore relativo dell' 1%,\n",
    "* k: numero di iterazioni successive che devono essere minori di $\\epsilon$ per fermare il ciclo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e0122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione Eulero - Monte Carlo:  24.765625\n",
      " \n",
      "Numero m di step per avere convergenza con M = 1000 :\n",
      " \n",
      "Tempo di esecuzione con r0=0.5 e rho=0.6:  54.734375\n",
      "Tempo di esecuzione con r0=0.5 e rho=0.7:  83.9375\n",
      "Tempo di esecuzione con r0=0.5 e rho=0.8:  181.984375\n",
      "Tempo di esecuzione con r0=0.5 e rho=0.9:  692.5\n",
      "Tempo di esecuzione con r0=1 e rho=0.6:  19.125\n",
      "Tempo di esecuzione con r0=1 e rho=0.7:  24.78125\n",
      "Tempo di esecuzione con r0=1 e rho=0.8:  28.875\n",
      "Tempo di esecuzione con r0=1 e rho=0.9:  49.15625\n",
      "Tempo di esecuzione con r0=5 e rho=0.6:  13.09375\n",
      "Tempo di esecuzione con r0=5 e rho=0.7:  12.03125\n",
      "Tempo di esecuzione con r0=5 e rho=0.8:  9.984375\n",
      "Tempo di esecuzione con r0=5 e rho=0.9:  13.0625\n",
      "Tempo di esecuzione con r0=10 e rho=0.6:  17.234375\n",
      "Tempo di esecuzione con r0=10 e rho=0.7:  19.21875\n",
      "Tempo di esecuzione con r0=10 e rho=0.8:  15.09375\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    # Parametri in Input Comuni\n",
    "    \n",
    "    sigma = 0.5\n",
    "    T = 1\n",
    "    N = 100\n",
    "    X0 = 0.5\n",
    "    \n",
    "    # Parametri in Input Eulero-Monte Carlo\n",
    "    \n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    aa1 = 1\n",
    "    aa2 = 1\n",
    "    N1 = 100 # 1000\n",
    "    M1 = 1000000\n",
    "    \n",
    "    # Parametri in Input Discesa Del Gradiente\n",
    "    \n",
    "    h = T / N\n",
    "    n = 5   \n",
    "    r0 = [0.5, 1, 5, 10]\n",
    "    rho = [0.6, 0.7, 0.8, 0.9]\n",
    "    eps = 0.01\n",
    "    p = 10\n",
    "    M = 1000 # 1, 10, 100, 1000, 10000 \n",
    "    tipo = 'lagrange'\n",
    "\n",
    "        \n",
    "    # Eulero Monte Carlo\n",
    "    \n",
    "    start = time.process_time()   # parte il cronometro\n",
    "    X, Gamma1, Gamma2 = monte_carlo(c1, c2, aa1, aa2, sigma, T, N1, M1, X0)\n",
    "    end = time.process_time()   # si ferma il cronometro\n",
    "    \n",
    "    print(\"Tempo di esecuzione Eulero - Monte Carlo: \", end - start)\n",
    "    print(\" \")\n",
    "    \n",
    "    gamma1 = np.array([Gamma1[i] for i in range(0, len(Gamma1), int(N1/N))])\n",
    "    gamma2 = np.array([Gamma2[i] for i in range(0, len(Gamma2), int(N1/N))])\n",
    "    \n",
    "    \n",
    "    # Discesa del Gradiente\n",
    "    \n",
    "    A1 = []\n",
    "    A2 = []\n",
    "    \n",
    "    a1_0, a2_0, g = base(T, N, n, X0, tipo)\n",
    "    m = np.zeros((len(rho), len(r0)*3+1))\n",
    "    m[:,0] = rho\n",
    "    \n",
    "    \n",
    "    print(\"Numero m di step per avere convergenza con M = \"+str(M)+\" :\")\n",
    "    print(\" \")\n",
    "\n",
    "    for i in range(len(r0)):\n",
    "        for j in range(len(rho)):\n",
    "            mm = [0] * p\n",
    "            start = time.process_time()   # parte il cronometro \n",
    "            for k in range(p):\n",
    "                AA1, AA2, mm[k] = discesa_stocastica_del_gradiente(a1_0, a2_0, n, r0[i], rho[j], sigma, N, M, X0, eps, h, g, gamma1, gamma2) \n",
    "            \n",
    "            m[j,3*i+1:3*i+4] = [min(mm), max(mm), mean(mm)]\n",
    "            end = time.process_time()   # si ferma il cronometro \n",
    "        \n",
    "            A1.append(AA1)\n",
    "            A2.append(AA2)       \n",
    "            print(\"Tempo di esecuzione con r0=\"+str(r0[i])+\" e rho=\"+str(rho[j])+\": \", end - start)\n",
    "            # print(\"Numero di step con r0=\"+str(r0[i])+\" e rho=\"+str(rho[j])+\": \", m[j,i+1])\n",
    "\n",
    "\n",
    "    l = [\"rho \\ r0\"]\n",
    "    for i in range(len(r0)):\n",
    "        l.append(\" \")\n",
    "        l.append(str(r0[i]))\n",
    "        l.append(\" \")\n",
    "    print(\" \")\n",
    "    print(tabulate(m[:,:], headers=l))\n",
    "    print(\" \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b2894",
   "metadata": {},
   "source": [
    "Grafico dell'approssimazione di $\\mathbb{E}[sen(X)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03823269",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "plt.title(\"Confronto MC [\" + str(M1) + \" simulazioni] e SGD\") \n",
    "plt.xlabel(\"Step temporali\") \n",
    "plt.ylabel(\"Evoluzione di E[sen(X)]\") \n",
    "# plt.ylim(0.4, 0.6) # se non c'è il grafico è molto zoomato\n",
    "plt.plot(np.dot(A1[9], g), label='(La)1(t)')\n",
    "plt.plot(gamma1, label='gamma1')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecfb50",
   "metadata": {},
   "source": [
    "Grafico dell'approssimazione di $\\mathbb{E}[cos(X)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ec2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "plt.title(\"Confronto MC [\" + str(M1) + \" simulazioni] e SGD\") \n",
    "plt.xlabel(\"Step temporali\") \n",
    "plt.ylabel(\"Evoluzione di E[cos(X)]\") \n",
    "# plt.ylim(0.8, 0.9) # se non c'è il grafico è molto zoomato\n",
    "plt.plot(np.dot(A2[9], g), label='(La)2(t)')\n",
    "plt.plot(gamma2, label='gamma2')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac198a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2f859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
